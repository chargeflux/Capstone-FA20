{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_log_df = pd.read_csv(\"min_max_log_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>program_name</th>\n",
       "      <th>config</th>\n",
       "      <th>cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raytrace</td>\n",
       "      <td>4,64k,1m,16m</td>\n",
       "      <td>0.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raytrace</td>\n",
       "      <td>4,32k,1m,16m</td>\n",
       "      <td>0.838413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raytrace</td>\n",
       "      <td>4,32k,2m,32m</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raytrace</td>\n",
       "      <td>4,64k,2m,32m</td>\n",
       "      <td>0.949523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,64k,1m,32m</td>\n",
       "      <td>0.398326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,32k,2m,32m</td>\n",
       "      <td>0.420648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,64k,2m,32m</td>\n",
       "      <td>0.397875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>8,32k,2m,32m</td>\n",
       "      <td>0.301434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,32k,1m,32m</td>\n",
       "      <td>0.420648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,64k,1m,16m</td>\n",
       "      <td>0.398326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,32k,2m,16m</td>\n",
       "      <td>0.420648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,64k,2m,16m</td>\n",
       "      <td>0.397875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>swaptions</td>\n",
       "      <td>4,32k,1m,16m</td>\n",
       "      <td>0.420648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,32k,2m,16m</td>\n",
       "      <td>0.026172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,32k,1m,16m</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,64k,1m,16m</td>\n",
       "      <td>0.026020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,64k,2m,16m</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,32k,1m,16m</td>\n",
       "      <td>0.026161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,32k,2m,16m</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,64k,2m,16m</td>\n",
       "      <td>0.026010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,64k,1m,16m</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,32k,2m,32m</td>\n",
       "      <td>0.026172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,32k,1m,32m</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,64k,1m,32m</td>\n",
       "      <td>0.026020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,64k,2m,32m</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,32k,1m,32m</td>\n",
       "      <td>0.026161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,32k,2m,32m</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>4,64k,2m,32m</td>\n",
       "      <td>0.026010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8,64k,1m,32m</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,64k,1m,16m</td>\n",
       "      <td>0.573238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,32k,1m,16m</td>\n",
       "      <td>0.814702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,64k,1m,32m</td>\n",
       "      <td>0.425663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,32k,2m,32m</td>\n",
       "      <td>0.826120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,64k,2m,32m</td>\n",
       "      <td>0.822679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>canneal</td>\n",
       "      <td>4,32k,1m,32m</td>\n",
       "      <td>0.814702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fluidanimate</td>\n",
       "      <td>4,32k,1m,16m</td>\n",
       "      <td>0.603548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fluidanimate</td>\n",
       "      <td>4,64k,2m,32m</td>\n",
       "      <td>0.688139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fluidanimate</td>\n",
       "      <td>4,32k,2m,32m</td>\n",
       "      <td>0.688416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    program_name        config    cycles\n",
       "0       raytrace  4,64k,1m,16m  0.641700\n",
       "1       raytrace  4,32k,1m,16m  0.838413\n",
       "2       raytrace  4,32k,2m,32m  1.000000\n",
       "3       raytrace  4,64k,2m,32m  0.949523\n",
       "4      swaptions  4,64k,1m,32m  0.398326\n",
       "5      swaptions  4,32k,2m,32m  0.420648\n",
       "6      swaptions  4,64k,2m,32m  0.397875\n",
       "7      swaptions  8,32k,2m,32m  0.301434\n",
       "8      swaptions  4,32k,1m,32m  0.420648\n",
       "9      swaptions  4,64k,1m,16m  0.398326\n",
       "10     swaptions  4,32k,2m,16m  0.420648\n",
       "11     swaptions  4,64k,2m,16m  0.397875\n",
       "12     swaptions  4,32k,1m,16m  0.420648\n",
       "13  blackscholes  4,32k,2m,16m  0.026172\n",
       "14  blackscholes  8,32k,1m,16m  0.000182\n",
       "15  blackscholes  4,64k,1m,16m  0.026020\n",
       "16  blackscholes  8,64k,2m,16m  0.000000\n",
       "17  blackscholes  4,32k,1m,16m  0.026161\n",
       "18  blackscholes  8,32k,2m,16m  0.000182\n",
       "19  blackscholes  4,64k,2m,16m  0.026010\n",
       "20  blackscholes  8,64k,1m,16m  0.000020\n",
       "21  blackscholes  4,32k,2m,32m  0.026172\n",
       "22  blackscholes  8,32k,1m,32m  0.000182\n",
       "23  blackscholes  4,64k,1m,32m  0.026020\n",
       "24  blackscholes  8,64k,2m,32m  0.000000\n",
       "25  blackscholes  4,32k,1m,32m  0.026161\n",
       "26  blackscholes  8,32k,2m,32m  0.000182\n",
       "27  blackscholes  4,64k,2m,32m  0.026010\n",
       "28  blackscholes  8,64k,1m,32m  0.000020\n",
       "29       canneal  4,64k,1m,16m  0.573238\n",
       "30       canneal  4,32k,1m,16m  0.814702\n",
       "31       canneal  4,64k,1m,32m  0.425663\n",
       "32       canneal  4,32k,2m,32m  0.826120\n",
       "33       canneal  4,64k,2m,32m  0.822679\n",
       "34       canneal  4,32k,1m,32m  0.814702\n",
       "35  fluidanimate  4,32k,1m,16m  0.603548\n",
       "36  fluidanimate  4,64k,2m,32m  0.688139\n",
       "37  fluidanimate  4,32k,2m,32m  0.688416"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "cimport numpy as np  # noqa\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "from surprise.utils import get_rng\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase\n",
    "from surprise.prediction_algorithms.predictions import PredictionImpossible\n",
    "\n",
    "class NMF(AlgoBase):\n",
    "    \"\"\"A collaborative filtering algorithm based on Non-negative Matrix\n",
    "    Factorization.\n",
    "    This algorithm is very similar to :class:`SVD`. The prediction\n",
    "    :math:`\\\\hat{r}_{ui}` is set as:\n",
    "    .. math::\n",
    "        \\hat{r}_{ui} = q_i^Tp_u,\n",
    "    where user and item factors are kept **positive**. Our implementation\n",
    "    follows that suggested in :cite:`NMF:2014`, which is equivalent to\n",
    "    :cite:`Zhang96` in its non-regularized form. Both are direct applications\n",
    "    of NMF for dense matrices :cite:`NMF_algo`.\n",
    "    The optimization procedure is a (regularized) stochastic gradient descent\n",
    "    with a specific choice of step size that ensures non-negativity of factors,\n",
    "    provided that their initial values are also positive.\n",
    "    At each step of the SGD procedure, the factors :math:`f` or user :math:`u`\n",
    "    and item :math:`i` are updated as follows:\n",
    "    .. math::\n",
    "        p_{uf} &\\\\leftarrow p_{uf} &\\cdot \\\\frac{\\\\sum_{i \\in I_u} q_{if}\n",
    "        \\\\cdot r_{ui}}{\\\\sum_{i \\in I_u} q_{if} \\\\cdot \\\\hat{r_{ui}} +\n",
    "        \\\\lambda_u |I_u| p_{uf}}\\\\\\\\\n",
    "        q_{if} &\\\\leftarrow q_{if} &\\cdot \\\\frac{\\\\sum_{u \\in U_i} p_{uf}\n",
    "        \\\\cdot r_{ui}}{\\\\sum_{u \\in U_i} p_{uf} \\\\cdot \\\\hat{r_{ui}} +\n",
    "        \\lambda_i |U_i| q_{if}}\\\\\\\\\n",
    "    where :math:`\\lambda_u` and :math:`\\lambda_i` are regularization\n",
    "    parameters.\n",
    "    This algorithm is highly dependent on initial values. User and item factors\n",
    "    are uniformly initialized between ``init_low`` and ``init_high``. Change\n",
    "    them at your own risks!\n",
    "    A biased version is available by setting the ``biased`` parameter to\n",
    "    ``True``. In this case, the prediction is set as\n",
    "    .. math::\n",
    "        \\hat{r}_{ui} = \\mu + b_u + b_i + q_i^Tp_u,\n",
    "    still ensuring positive factors. Baselines are optimized in the same way as\n",
    "    in the :class:`SVD` algorithm. While yielding better accuracy, the biased\n",
    "    version seems highly prone to overfitting so you may want to reduce the\n",
    "    number of factors (or increase regularization).\n",
    "    Args:\n",
    "        n_factors: The number of factors. Default is ``15``.\n",
    "        n_epochs: The number of iteration of the SGD procedure. Default is\n",
    "            ``50``.\n",
    "        biased(bool): Whether to use baselines (or biases). Default is\n",
    "            ``False``.\n",
    "        reg_pu: The regularization term for users :math:`\\lambda_u`. Default is\n",
    "            ``0.06``.\n",
    "        reg_qi: The regularization term for items :math:`\\lambda_i`. Default is\n",
    "            ``0.06``.\n",
    "        reg_bu: The regularization term for :math:`b_u`. Only relevant for\n",
    "            biased version. Default is ``0.02``.\n",
    "        reg_bi: The regularization term for :math:`b_i`. Only relevant for\n",
    "            biased version. Default is ``0.02``.\n",
    "        lr_bu: The learning rate for :math:`b_u`. Only relevant for biased\n",
    "            version. Default is ``0.005``.\n",
    "        lr_bi: The learning rate for :math:`b_i`. Only relevant for biased\n",
    "            version. Default is ``0.005``.\n",
    "        init_low: Lower bound for random initialization of factors. Must be\n",
    "            greater than ``0`` to ensure non-negative factors. Default is\n",
    "            ``0``.\n",
    "        init_high: Higher bound for random initialization of factors. Default\n",
    "            is ``1``.\n",
    "        random_state(int, RandomState instance from numpy, or ``None``):\n",
    "            Determines the RNG that will be used for initialization. If\n",
    "            int, ``random_state`` will be used as a seed for a new RNG. This is\n",
    "            useful to get the same initialization over multiple calls to\n",
    "            ``fit()``.  If RandomState instance, this same instance is used as\n",
    "            RNG. If ``None``, the current RNG from numpy is used.  Default is\n",
    "            ``None``.\n",
    "        verbose: If ``True``, prints the current epoch. Default is ``False``.\n",
    "    Attributes:\n",
    "        pu(numpy array of size (n_users, n_factors)): The user factors (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        qi(numpy array of size (n_items, n_factors)): The item factors (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        bu(numpy array of size (n_users)): The user biases (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        bi(numpy array of size (n_items)): The item biases (only\n",
    "            exists if ``fit()`` has been called)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_factors=15, n_epochs=50, biased=False, reg_pu=.06,\n",
    "                 reg_qi=.06, reg_bu=.02, reg_bi=.02, lr_bu=.005, lr_bi=.005,\n",
    "                 init_low=0, init_high=1, random_state=None, verbose=False):\n",
    "\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.biased = biased\n",
    "        self.reg_pu = reg_pu\n",
    "        self.reg_qi = reg_qi\n",
    "        self.lr_bu = lr_bu\n",
    "        self.lr_bi = lr_bi\n",
    "        self.reg_bu = reg_bu\n",
    "        self.reg_bi = reg_bi\n",
    "        self.init_low = init_low\n",
    "        self.init_high = init_high\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.init_low < 0:\n",
    "            raise ValueError('init_low should be greater than zero')\n",
    "\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        self.sgd(trainset)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def sgd(self, trainset):\n",
    "\n",
    "        # user and item factors\n",
    "        cdef np.ndarray[np.double_t, ndim=2] pu\n",
    "        cdef np.ndarray[np.double_t, ndim=2] qi\n",
    "\n",
    "        # user and item biases\n",
    "        cdef np.ndarray[np.double_t] bu\n",
    "        cdef np.ndarray[np.double_t] bi\n",
    "\n",
    "        # auxiliary matrices used in optimization process\n",
    "        cdef np.ndarray[np.double_t, ndim=2] user_num\n",
    "        cdef np.ndarray[np.double_t, ndim=2] user_denom\n",
    "        cdef np.ndarray[np.double_t, ndim=2] item_num\n",
    "        cdef np.ndarray[np.double_t, ndim=2] item_denom\n",
    "\n",
    "        cdef int u, i, f\n",
    "        cdef double r, est, l, dot, err\n",
    "        cdef double reg_pu = self.reg_pu\n",
    "        cdef double reg_qi = self.reg_qi\n",
    "        cdef double reg_bu = self.reg_bu\n",
    "        cdef double reg_bi = self.reg_bi\n",
    "        cdef double lr_bu = self.lr_bu\n",
    "        cdef double lr_bi = self.lr_bi\n",
    "        cdef double global_mean = self.trainset.global_mean\n",
    "\n",
    "        # Randomly initialize user and item factors\n",
    "        rng = get_rng(self.random_state)\n",
    "        pu = rng.uniform(self.init_low, self.init_high,\n",
    "                         size=(trainset.n_users, self.n_factors))\n",
    "        qi = rng.uniform(self.init_low, self.init_high,\n",
    "                         size=(trainset.n_items, self.n_factors))\n",
    "\n",
    "        bu = np.zeros(trainset.n_users, np.double)\n",
    "        bi = np.zeros(trainset.n_items, np.double)\n",
    "\n",
    "        if not self.biased:\n",
    "            global_mean = 0\n",
    "\n",
    "        for current_epoch in range(self.n_epochs):\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Processing epoch {}\".format(current_epoch))\n",
    "\n",
    "            # (re)initialize nums and denoms to zero\n",
    "            user_num = np.zeros((trainset.n_users, self.n_factors))\n",
    "            user_denom = np.zeros((trainset.n_users, self.n_factors))\n",
    "            item_num = np.zeros((trainset.n_items, self.n_factors))\n",
    "            item_denom = np.zeros((trainset.n_items, self.n_factors))\n",
    "\n",
    "            # Compute numerators and denominators for users and items factors\n",
    "            for u, i, r in trainset.all_ratings():\n",
    "\n",
    "                # compute current estimation and error\n",
    "                dot = 0  # <q_i, p_u>\n",
    "                for f in range(self.n_factors):\n",
    "                    dot += qi[i, f] * pu[u, f]\n",
    "                est = global_mean + bu[u] + bi[i] + dot\n",
    "                err = r - est\n",
    "\n",
    "                # update biases\n",
    "                if self.biased:\n",
    "                    bu[u] += lr_bu * (err - reg_bu * bu[u])\n",
    "                    bi[i] += lr_bi * (err - reg_bi * bi[i])\n",
    "\n",
    "                # compute numerators and denominators\n",
    "                for f in range(self.n_factors):\n",
    "                    user_num[u, f] += qi[i, f] * r\n",
    "                    user_denom[u, f] += qi[i, f] * est\n",
    "                    item_num[i, f] += pu[u, f] * r\n",
    "                    item_denom[i, f] += pu[u, f] * est\n",
    "\n",
    "            # Update user factors\n",
    "            for u in trainset.all_users():\n",
    "                n_ratings = len(trainset.ur[u])\n",
    "                for f in range(self.n_factors):\n",
    "                    user_denom[u, f] += n_ratings * reg_pu * pu[u, f]\n",
    "                    if user_denom[u,f] != 0: # check if not 0 to prevent div by 0\n",
    "                        pu[u, f] *= user_num[u, f] / user_denom[u, f]\n",
    "\n",
    "            # Update item factors\n",
    "            for i in trainset.all_items():\n",
    "                n_ratings = len(trainset.ir[i])\n",
    "                for f in range(self.n_factors):\n",
    "                    item_denom[i, f] += n_ratings * reg_qi * qi[i, f]\n",
    "                    if item_denom[i,f] != 0: # check if not 0 to prevent div by 0\n",
    "                        qi[i, f] *= item_num[i, f] / item_denom[i, f]\n",
    "\n",
    "        self.bu = bu\n",
    "        self.bi = bi\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        # Should we cythonize this as well?\n",
    "\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "\n",
    "        if self.biased:\n",
    "            est = self.trainset.global_mean\n",
    "\n",
    "            if known_user:\n",
    "                est += self.bu[u]\n",
    "\n",
    "            if known_item:\n",
    "                est += self.bi[i]\n",
    "\n",
    "            if known_user and known_item:\n",
    "                est += np.dot(self.qi[i], self.pu[u])\n",
    "\n",
    "        else:\n",
    "            if known_user and known_item:\n",
    "                est = np.dot(self.qi[i], self.pu[u])\n",
    "            else:\n",
    "                raise PredictionImpossible('User and item are unknown.')\n",
    "\n",
    "        return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [10, 20, 50], # 20 is default\n",
    "              'n_factors': [5, 10, 15, 20, 50], # 15 is default\n",
    "              'lr_bu': [5e-3, 1e-2, 5e-2, 1e-1], # 0.005\n",
    "              'lr_bi': [5e-3, 1e-2, 5e-2, 1e-1], # 0.005\n",
    "              'reg_pu': [1e-3, 1e-2, 6e-2, 1e-1], # 0.06\n",
    "              'reg_qi': [1e-3, 1e-2, 6e-2, 1e-1], # 0.06\n",
    "              'reg_bu': [1e-3, 1e-2, 2e-2, 1e-1], # 0.02\n",
    "              'reg_bi': [1e-3, 1e-2, 2e-2, 1e-1], # 0.02\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_NMF = partial(NMF, biased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = surprise.model_selection.GridSearchCV(biased_NMF, param_grid, measures=['rmse'], cv=5, return_train_measures=True)\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(min_max_log_df[min_max_log_df.program_name != 'fluidanimate'], reader)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06202944876539507\n",
      "{'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.06, 'reg_qi': 0.01, 'reg_bu': 0.001, 'reg_bi': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>mean_train_rmse</th>\n",
       "      <th>std_train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.080805</td>\n",
       "      <td>0.100696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43209</th>\n",
       "      <td>0.067193</td>\n",
       "      <td>0.032398</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.032164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22655</th>\n",
       "      <td>0.068064</td>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.042055</td>\n",
       "      <td>0.013312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43369</th>\n",
       "      <td>0.069918</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.024559</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44467</th>\n",
       "      <td>0.070606</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.097113</td>\n",
       "      <td>0.070105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22985</th>\n",
       "      <td>0.071322</td>\n",
       "      <td>0.041437</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.047413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43127</th>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.036581</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>0.034165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43226</th>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.037790</td>\n",
       "      <td>0.033809</td>\n",
       "      <td>0.004641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>0.072367</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.100568</td>\n",
       "      <td>0.054403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22924</th>\n",
       "      <td>0.072530</td>\n",
       "      <td>0.028052</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>0.049545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_test_rmse  std_test_rmse  mean_train_rmse  std_train_rmse\n",
       "43409        0.062029       0.024659         0.080805        0.100696\n",
       "43209        0.067193       0.032398         0.041817        0.032164\n",
       "22655        0.068064       0.026184         0.042055        0.013312\n",
       "43369        0.069918       0.037658         0.024559        0.001767\n",
       "44467        0.070606       0.007286         0.097113        0.070105\n",
       "22985        0.071322       0.041437         0.048729        0.047413\n",
       "43127        0.071929       0.036581         0.055599        0.034165\n",
       "43226        0.072170       0.037790         0.033809        0.004641\n",
       "3492         0.072367       0.027211         0.100568        0.054403\n",
       "22924        0.072530       0.028052         0.052303        0.049545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\").iloc[:10,10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43409    {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.06, 'reg_qi': 0.01, 'reg_bu': 0.001, 'reg_bi': 0.01}\n",
       "43209    {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.005, 'reg_pu': 0.1, 'reg_qi': 0.001, 'reg_bu': 0.02, 'reg_bi': 0.01}\n",
       "22655       {'n_epochs': 20, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.005, 'reg_pu': 0.01, 'reg_qi': 0.1, 'reg_bu': 0.1, 'reg_bi': 0.1}\n",
       "43369     {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.01, 'reg_qi': 0.06, 'reg_bu': 0.02, 'reg_bi': 0.01}\n",
       "44467       {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.1, 'lr_bi': 0.01, 'reg_pu': 0.06, 'reg_qi': 0.1, 'reg_bu': 0.001, 'reg_bi': 0.1}\n",
       "22985     {'n_epochs': 20, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.1, 'reg_qi': 0.001, 'reg_bu': 0.02, 'reg_bi': 0.01}\n",
       "43127      {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.005, 'reg_pu': 0.01, 'reg_qi': 0.1, 'reg_bu': 0.01, 'reg_bi': 0.1}\n",
       "43226     {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.005, 'reg_pu': 0.1, 'reg_qi': 0.01, 'reg_bu': 0.02, 'reg_bi': 0.02}\n",
       "3492      {'n_epochs': 10, 'n_factors': 5, 'lr_bu': 0.1, 'lr_bi': 0.01, 'reg_pu': 0.06, 'reg_qi': 0.06, 'reg_bu': 0.01, 'reg_bi': 0.001}\n",
       "22924    {'n_epochs': 20, 'n_factors': 5, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.06, 'reg_qi': 0.001, 'reg_bu': 0.1, 'reg_bi': 0.001}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\")[\"params\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can get comparable performance between 20 and 50 epochs at 5 factors, suggesting that we can explore epochs in this range. 10 epochs seem to underfit and is dependent on more factors for good performance. The gap between mean test and train RMSE is about 0.021 for the second best configuration. It is interesting the mean training RMSE is greater than the mean test RMSE for the best configuration but it also has a large standard deviation for the train std RMSE. The best learning rate seems to be between 0.05 and 0.1 (row 44467) and between 0.005 and 0.01 for the user and item biases respectively. We can also consider a reg_pu value betwen 0.01 and 0.1, reg_qi around 0.06 and 0.001, reg_bu around 0.02, 0.001 and 0.1 and reg_bi between 0.01 and 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [20, 30, 40, 50, 60], # 20 is default\n",
    "              'n_factors': [3, 5, 7], # 15 is default\n",
    "              'lr_bu': [0.03, 0.05, 0.07, 0.1], # 0.005\n",
    "              'lr_bi': [0.003, 0.005, 0.007, 0.01], # 0.005\n",
    "              'reg_pu': [0.01, 0.05, 0.08, 0.1], # 0.06\n",
    "              'reg_qi': [0.001, 0.005, 0.01, 0.03, 0.06, 0.08], # 0.06\n",
    "              'reg_bu': [0.001, 0.005, 0.01, 0.05, 0.1], # 0.02\n",
    "              'reg_bi': [0.01, 0.03, 0.05, 0.07, 0.1], # 0.02\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = surprise.model_selection.GridSearchCV(biased_NMF, param_grid, measures=['rmse'], cv=5, return_train_measures=True)\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(min_max_log_df[min_max_log_df.program_name != 'fluidanimate'], reader)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04530279422343848\n",
      "{'n_epochs': 60, 'n_factors': 3, 'lr_bu': 0.07, 'lr_bi': 0.005, 'reg_pu': 0.05, 'reg_qi': 0.001, 'reg_bu': 0.001, 'reg_bi': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>mean_train_rmse</th>\n",
       "      <th>std_train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120752</th>\n",
       "      <td>0.045303</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.028017</td>\n",
       "      <td>0.029391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61237</th>\n",
       "      <td>0.045813</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.002438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87604</th>\n",
       "      <td>0.046312</td>\n",
       "      <td>0.017352</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.002785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0.046738</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>0.006364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37362</th>\n",
       "      <td>0.047152</td>\n",
       "      <td>0.023478</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.005681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29405</th>\n",
       "      <td>0.048494</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97993</th>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.019591</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>0.033857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123155</th>\n",
       "      <td>0.049148</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.046227</td>\n",
       "      <td>0.043296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62259</th>\n",
       "      <td>0.050802</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_test_rmse  std_test_rmse  mean_train_rmse  std_train_rmse\n",
       "120752        0.045303       0.022758         0.028017        0.029391\n",
       "61237         0.045813       0.018138         0.012238        0.002438\n",
       "87604         0.046312       0.017352         0.008903        0.002785\n",
       "1807          0.046738       0.019381         0.016110        0.006364\n",
       "37362         0.047152       0.023478         0.017943        0.005681\n",
       "29405         0.048494       0.022929         0.011408        0.003592\n",
       "97993         0.049001       0.019591         0.038899        0.033857\n",
       "123155        0.049148       0.014500         0.046227        0.043296\n",
       "5101          0.049755       0.020646         0.019143        0.003235\n",
       "62259         0.050802       0.017235         0.017071        0.004345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\").iloc[:10,10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120752    {'n_epochs': 60, 'n_factors': 3, 'lr_bu': 0.07, 'lr_bi': 0.005, 'reg_pu': 0.05, 'reg_qi': 0.001, 'reg_bu': 0.001, 'reg_bi': 0.05}\n",
       "61237      {'n_epochs': 40, 'n_factors': 3, 'lr_bu': 0.05, 'lr_bi': 0.007, 'reg_pu': 0.01, 'reg_qi': 0.005, 'reg_bu': 0.01, 'reg_bi': 0.05}\n",
       "87604      {'n_epochs': 50, 'n_factors': 3, 'lr_bu': 0.03, 'lr_bi': 0.007, 'reg_pu': 0.01, 'reg_qi': 0.001, 'reg_bu': 0.001, 'reg_bi': 0.1}\n",
       "1807       {'n_epochs': 20, 'n_factors': 3, 'lr_bu': 0.03, 'lr_bi': 0.01, 'reg_pu': 0.01, 'reg_qi': 0.001, 'reg_bu': 0.005, 'reg_bi': 0.05}\n",
       "37362       {'n_epochs': 30, 'n_factors': 3, 'lr_bu': 0.1, 'lr_bi': 0.007, 'reg_pu': 0.05, 'reg_qi': 0.001, 'reg_bu': 0.01, 'reg_bi': 0.05}\n",
       "29405     {'n_epochs': 30, 'n_factors': 3, 'lr_bu': 0.03, 'lr_bi': 0.005, 'reg_pu': 0.01, 'reg_qi': 0.001, 'reg_bu': 0.005, 'reg_bi': 0.01}\n",
       "97993       {'n_epochs': 50, 'n_factors': 5, 'lr_bu': 0.03, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.005, 'reg_bu': 0.05, 'reg_bi': 0.07}\n",
       "123155     {'n_epochs': 60, 'n_factors': 3, 'lr_bu': 0.1, 'lr_bi': 0.005, 'reg_pu': 0.05, 'reg_qi': 0.001, 'reg_bu': 0.005, 'reg_bi': 0.01}\n",
       "5101      {'n_epochs': 20, 'n_factors': 3, 'lr_bu': 0.07, 'lr_bi': 0.003, 'reg_pu': 0.08, 'reg_qi': 0.001, 'reg_bu': 0.001, 'reg_bi': 0.03}\n",
       "62259        {'n_epochs': 40, 'n_factors': 3, 'lr_bu': 0.05, 'lr_bi': 0.01, 'reg_pu': 0.1, 'reg_qi': 0.001, 'reg_bu': 0.005, 'reg_bi': 0.1}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\")[\"params\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epochs seems ideal because we can achieve comparable performance with a difference of about 0.001 in mean test RMSE  with the best configuration and a closer gap between mean test and train RMSE to avoid overfitting. 3 factors seem sufficient to achieve the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best configuration seems to be 20 epochs with 3 factors, a learning rate of 0.03 and 0.01 for user and item biases, a regularization factor of 0.01, 0.001, 0.005, 0.05 for pu, qi, bu and bi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF without Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [10, 20, 50], # 20 is default\n",
    "              'n_factors': [5, 10, 15, 20, 50], # 15 is default\n",
    "              'reg_pu': [1e-3, 1e-2, 6e-2, 1e-1], # 0.06\n",
    "              'reg_qi': [1e-3, 1e-2, 6e-2, 1e-1] # 0.06\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = surprise.model_selection.GridSearchCV(NMF, param_grid, measures=['rmse'], cv=5, return_train_measures=True)\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(min_max_log_df[min_max_log_df.program_name != 'fluidanimate'], reader)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>mean_train_rmse</th>\n",
       "      <th>std_train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.181977</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.025102</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.183961</td>\n",
       "      <td>0.043918</td>\n",
       "      <td>0.032206</td>\n",
       "      <td>0.003256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.184890</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>0.071562</td>\n",
       "      <td>0.004462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.184893</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.004686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.185165</td>\n",
       "      <td>0.044711</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.185806</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.074811</td>\n",
       "      <td>0.007193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.185966</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.005990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.186281</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.186289</td>\n",
       "      <td>0.033522</td>\n",
       "      <td>0.062156</td>\n",
       "      <td>0.006830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_rmse  std_test_rmse  mean_train_rmse  std_train_rmse\n",
       "188        0.181977       0.039122         0.025102        0.002590\n",
       "213        0.182540       0.039124         0.084578        0.006640\n",
       "179        0.183961       0.043918         0.032206        0.003256\n",
       "178        0.184890       0.041107         0.071562        0.004462\n",
       "204        0.184893       0.033717         0.036551        0.004686\n",
       "87         0.185165       0.044711         0.024444        0.003312\n",
       "227        0.185806       0.038575         0.074811        0.007193\n",
       "184        0.185966       0.030562         0.056986        0.005990\n",
       "157        0.186281       0.041225         0.031327        0.005376\n",
       "236        0.186289       0.033522         0.062156        0.006830"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\").iloc[:10,10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188     {'n_epochs': 50, 'n_factors': 10, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "213     {'n_epochs': 50, 'n_factors': 20, 'reg_pu': 0.01, 'reg_qi': 0.01}\n",
       "179     {'n_epochs': 50, 'n_factors': 10, 'reg_pu': 0.001, 'reg_qi': 0.1}\n",
       "178    {'n_epochs': 50, 'n_factors': 10, 'reg_pu': 0.001, 'reg_qi': 0.06}\n",
       "204     {'n_epochs': 50, 'n_factors': 15, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "87        {'n_epochs': 20, 'n_factors': 5, 'reg_pu': 0.01, 'reg_qi': 0.1}\n",
       "227     {'n_epochs': 50, 'n_factors': 50, 'reg_pu': 0.001, 'reg_qi': 0.1}\n",
       "184    {'n_epochs': 50, 'n_factors': 10, 'reg_pu': 0.06, 'reg_qi': 0.001}\n",
       "157      {'n_epochs': 20, 'n_factors': 50, 'reg_pu': 0.1, 'reg_qi': 0.01}\n",
       "236     {'n_epochs': 50, 'n_factors': 50, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\")[\"params\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [20, 25, 30, 35, 40, 45, 50], # 20 is default\n",
    "              'n_factors': [25, 30, 35, 40, 45, 50], # 15 is default\n",
    "              'reg_pu': [1e-3, 1e-2, 6e-2, 1e-1], # 0.06\n",
    "              'reg_qi': [1e-3, 1e-2, 6e-2, 1e-1] # 0.06\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = surprise.model_selection.GridSearchCV(NMF, param_grid, measures=['rmse'], cv=5, return_train_measures=True)\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(min_max_log_df[min_max_log_df.program_name != 'fluidanimate'], reader)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>mean_train_rmse</th>\n",
       "      <th>std_train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.220899</td>\n",
       "      <td>0.051941</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.220952</td>\n",
       "      <td>0.048529</td>\n",
       "      <td>0.061274</td>\n",
       "      <td>0.005936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.221016</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.048376</td>\n",
       "      <td>0.002808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.221217</td>\n",
       "      <td>0.047381</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.009412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.221589</td>\n",
       "      <td>0.051372</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>0.003436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.221620</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>0.072143</td>\n",
       "      <td>0.006784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.221759</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>0.005310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.221807</td>\n",
       "      <td>0.048787</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222064</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>0.061993</td>\n",
       "      <td>0.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.222769</td>\n",
       "      <td>0.055704</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.003210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_rmse  std_test_rmse  mean_train_rmse  std_train_rmse\n",
       "93         0.220899       0.051941         0.028712        0.003962\n",
       "668        0.220952       0.048529         0.061274        0.005936\n",
       "588        0.221016       0.050537         0.048376        0.002808\n",
       "652        0.221217       0.047381         0.061333        0.009412\n",
       "201        0.221589       0.051372         0.023203        0.003436\n",
       "57         0.221620       0.046220         0.072143        0.006784\n",
       "396        0.221759       0.048010         0.070335        0.005310\n",
       "25         0.221807       0.048787         0.067718        0.007999\n",
       "9          0.222064       0.051187         0.061993        0.011601\n",
       "214        0.222769       0.055704         0.024667        0.003210"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\").iloc[:10,10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93      {'n_epochs': 20, 'n_factors': 50, 'reg_pu': 0.1, 'reg_qi': 0.01}\n",
       "668    {'n_epochs': 50, 'n_factors': 50, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "588    {'n_epochs': 50, 'n_factors': 25, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "652    {'n_epochs': 50, 'n_factors': 45, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "201    {'n_epochs': 30, 'n_factors': 25, 'reg_pu': 0.06, 'reg_qi': 0.01}\n",
       "57     {'n_epochs': 20, 'n_factors': 40, 'reg_pu': 0.06, 'reg_qi': 0.01}\n",
       "396    {'n_epochs': 40, 'n_factors': 25, 'reg_pu': 0.1, 'reg_qi': 0.001}\n",
       "25     {'n_epochs': 20, 'n_factors': 30, 'reg_pu': 0.06, 'reg_qi': 0.01}\n",
       "9      {'n_epochs': 20, 'n_factors': 25, 'reg_pu': 0.06, 'reg_qi': 0.01}\n",
       "214    {'n_epochs': 30, 'n_factors': 30, 'reg_pu': 0.01, 'reg_qi': 0.06}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).sort_values(\"mean_test_rmse\")[\"params\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that NMF without bias can not outperform with bias despite hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python36864bitbaseconda4f0362790c5a45a68cbb456d37abe7ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
